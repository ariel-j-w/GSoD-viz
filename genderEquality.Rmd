---
title: "Predictors of Gender Equality"
author: "Ariel Wentworth"
date: "January 2021"
output: pdf_document
---

```{r}
library(tidyverse)
library(rpart)
library(rpart.plot)
library(ggplot2)
library(showtext)
library(formattable)
```

```{r}
showtext_auto()
font_add_google(name = 'Lato', family = 'lato')
```

# Predictors of Gender Equality

In this file, we explore predictors of gender equality based on the [Global State of Democracy Index](https://www.idea.int/gsod-indices/dataset-resources) (hereafter GSoDi). All data has been [mildly pre-processed](https://github.com/ariel-j-w/GSoD-viz/blob/main/pre-processing.ipynb) already, and here we work through the decision tree analysis in order to identify which indicators are predictive of gender equality. Working with the variables in this dataset will be key for this analysis, so I recommend keeping [a cheat sheet](https://github.com/ariel-j-w/GSoD-viz/blob/main/Global%20State%20of%20Democracy%20Index%202020.png) on hand to remind yourself of the variables' meanings.

In `exploration.Rmd`, I started to explore this question, but gave up on it due to the complexity of decision trees when the output variable is continuous. After some more thought, I wanted to return to the question with a new approach. Thus, in this notebook we will endeavor to use decision trees to answer the question: Which Global State of Democracy variables are the best predictors of gender equality?

To start, we load in our data. 60% of the original data is in `trainData`, which we will use to train our models. Another 20% of the data is in `queryData`, which we will use to test accuracy of our trained models, aiding our decision in what level of data granularity to use. Finally, `testData` will only be used to estimate the accuracy of our final trained model.

```{r}
countries <- read_csv('data/complete-countries.csv')
trainData <- read_csv('data/train-countries.csv')
queryData <- read_csv('data/query-countries.csv')
testData <- read_csv('data/test-countries.csv')
```

We first define a couple of functions (`plot_imp` and `fit_accuracy`) that will be useful as we go along to quickly plot the variable importance chart and to estimate model accuracy using query data.

```{r}
plot_imp <- function(fit) {
  fit.imp <- rownames_to_column(data.frame(fit$variable.importance))
  names(fit.imp)[1] <- "variable"
  names(fit.imp)[2] <- "importance"
  fit.imp <- mutate(fit.imp, variable = fct_reorder(variable, importance))
  
  ggplot(fit.imp) +
    geom_segment(aes(x = variable, y = 0, xend = variable, yend = importance)) +
    geom_point(aes(x = variable, y = importance, color = variable, size = 1.2), show.legend = FALSE) + 
    coord_flip()
}
```

```{r}
fit_accuracy <- function(fit) {
  pred <- predict(fit, queryData, type = "vector")
  confusionMatrix <- table(queryData$genderEqBin, pred)
  accuracy <- sum(diag(confusionMatrix))/sum(confusionMatrix)
  accuracy
}
```

In order to use classification trees for this analysis (and reduce complexity of determining accuracy and best fit), we will bin our data into 4 bins of gender equalaity ratings.

```{r}
trainData <- trainData %>%
  mutate(genderEqBin = cut(C_SD23C, breaks = c(-Inf, 0.4, 0.6, 0.8, 1)))
# head(trainData, 500)[, c('ID_country_name', 'ID_year', 'C_SD23C', 'genderEqBin')]

queryData <- queryData %>%
  mutate(genderEqBin = cut(C_SD23C, breaks = c(-Inf, 0.4, 0.6, 0.8, 1)))

testData <- testData %>%
  mutate(genderEqBin = cut(C_SD23C, breaks = c(-Inf, 0.4, 0.6, 0.8, 1)))
```


## Decision Tree

There are so many different levels of data granularity, that one of our main objectives will be to determine which level of data is going to be the most effective for prediction. We decided to start with the highest level of abstraction, and use decision tree analysis at this level to inform our decisions for what variables to include as we slowly work into more granular data.

Thus, we start with this decision tree at the domain level, including domains 1 (representative government), 3 (checks on government), and 4 (impartial administration). We exclude domain 5 (participatory engagement) because the GSoDi defines no aggregate measure for this domain. We also exlcude domain 2 (fundamental rights) because gender equality is a sub-variable under domain 2, and since gender equality is thus part of the measurement that directly determines the measure for fundamental rights, including it here would be inappropriate.

```{r}
domains.fit <- rpart(genderEqBin ~ C_A1+C_A3+C_A4, data = trainData)
# summary(domains.fit)
rpart.plot(domains.fit)
```

```{r}
fit_accuracy(domains.fit)
```


```{r}
plot_imp(domains.fit)
```

The variable importance chart reveals that there isn't a huge difference between the importance for these domains, so we include all of their subdomains in our next analysis. We also add in the subdomains from domains 2 and 5, but exclude subdomain 2.3 (social rights and equality) since gender equality is one of the variables aggregated by subdomain 2.3.

```{r}
subdomains.fit <- rpart(genderEqBin ~ C_SD11+C_SD12+C_SD13+C_SD14+C_SD21+C_SD22+C_SD31+C_SD32+C_SD33+
                                         C_SD41+C_SD42+C_SD51+C_SD52+C_SD53+C_SD54, data = trainData)
rpart.plot(subdomains.fit)
```

```{r}
plot_imp(subdomains.fit)
```

```{r}
fit_accuracy(subdomains.fit)
```

Based on the variable importance chart above, we can see that there is a clear difference between the importance of the first 6 subdomains listed and the rest of the variables. For our next step, we include only these 6 subdomains, expanding subdomain 2.2 into its A-E parts and adding parts A (social group equality) and B (basic welfare) of subdomain 2.3 (social rights and equality). Remember that 2.3 was not included in our previous step since gender equality (our output variable, i.e. 2.3C) is part of the definition of 2.3, but since gender equality does not aggregate into 2.3A or 2.3B, we can include them here.

```{r}
subsubdomains.fit <- rpart(genderEqBin ~ C_SD22A+C_SD22B+C_SD22C+C_SD22D+C_SD22E+C_SD13+
                                            C_SD21+C_SD33+C_SD42+C_SD32+C_SD23A+C_SD23B, data = trainData)
rpart.plot(subsubdomains.fit)
```

```{r}
plot_imp(subsubdomains.fit)
```

```{r}
fit_accuracy(subsubdomains.fit)
```

We are up to almost 76% accuracy, which is exciting! We can also see from the above variable importance chart that the first six variables listed (2.3A, 2.2A, 2.1, 4.2, 2.2E, and 2.2D) are significantly more important than their counterparts in predicting gender equality. Thus, we go one more step of looking at a decision tree with the individual indicators which ultimately aggregate into these variables.

```{r}
variables.fit <- rpart(genderEqBin ~
                         v_23_01+v_23_02+v_23_03+v_23_04+v_23_05+v_23_06+v_23_07+v_23_08+v_23_09+v_23_10+
                         v_22_01+v_22_02+v_22_03+v_22_04+v_22_05+v_22_06+v_22_07+v_22_08+
                         v_21_01+v_21_02+v_21_03+v_21_04+v_21_05+
                         v_42_01+v_42_02+v_42_03+v_42_04+v_42_06+
                         v_22_41+v_22_42+v_22_43+v_22_44+v_22_45+v_22_46+v_22_47+ 
                         v_22_31+v_22_32+v_22_33+v_22_34+v_22_35,
                       data = trainData)
rpart.plot(variables.fit)
```

```{r}
plot_imp(variables.fit)
```

```{r}
fit_accuracy(variables.fit)
```

Wow, we are up to nearly 78% accuracy! That's great, but there are a ton of variables in this decision tree. I'm worried that we are most likely overfitting the data as is. For this reason, we are going to "prune" our tree, and remove the variables which contribute to less than 1% of the overall importance. This way, we should keep the most important predictors while slimming down our tree.

```{r}
imp <- rownames_to_column(data.frame(variables.fit$variable.importance))
names(imp)[1] <- "variable"
names(imp)[2] <- "importance"

imp %>% mutate(relativeImportance = importance/sum(importance))
```

```{r}
pruned.fit <- rpart(genderEqBin ~ v_23_08+v_23_09+v_23_06+v_23_07+v_21_02+v_21_01+v_23_02+v_23_04+
                      v_22_06+v_22_31+v_22_32+v_22_33+v_22_05+v_22_03+v_22_01, data = trainData)
rpart.plot(pruned.fit, box.palette = 'Greys') 
```

```{r}
plot_imp(pruned.fit)
```

```{r}
fit_accuracy(pruned.fit)
```

Great! We still have 74.78% accuracy in our pruned tree according to query data, but it's appropriate now to pull out the test data to get a more true measure of accuracy. This step, of checking accuracy with a dataset that has not at all influenced model selection, is important to get our best possible guess for how our model will do with new, previously unseen "real world" data. This type of check might also help us detect overfitting.

```{r}
pred <- predict(pruned.fit, testData, type = "vector")
confusionMatrix <- table(testData$genderEqBin, pred)
accuracy <- sum(diag(confusionMatrix))/sum(confusionMatrix)
accuracy
```

Nearly 77% accuracy seems really great to me! Another metric I was interested in was how often this tree classifies an observation into either its correct bin or an adjacent one. As a general sense, how often does this decision tree "get close"? 

```{r}
pred <- predict(pruned.fit, testData, type = "vector")
confusionMatrix <- table(testData$genderEqBin, pred)
psuedoAccuracy <- (sum(diag(confusionMatrix))+confusionMatrix[2,1]+confusionMatrix[1,2]+
  confusionMatrix[3,2]+confusionMatrix[2,3]+confusionMatrix[4,3]+confusionMatrix[3,4])/sum(confusionMatrix)
psuedoAccuracy
```

Over 99% of the time this model accurately predicts either an observations bin or its adjacent bin! Wow! It's really encouraging to know that there is less than 1% of the time that the classifier will be just completely wrong.

We now do a little bit of work to clean up our variable importance visualization and save it to a png.

```{r}
imp <- rownames_to_column(data.frame(pruned.fit$variable.importance))
names(imp)[1] <- "variable"
names(imp)[2] <- "importance"
imp %>% 
  mutate(variable = fct_reorder(variable, importance)) %>%
  mutate(feature = c('Exclusion by social group index (inverted)',
                     'Exculsion by urban/rural location (inverted)',
                     'Exclusion by socio-economic group (inverted)',
                     'Exclusion by political group index (inverted)',
                     'Access to justice for women',
                     'Access to justice for men',
                     'Social group equality in respect to civil liberties',
                     'Power distributed by social group',
                     'Freedom of foreign movement',
                     'Freedom of academic and cultural expression',
                     'Freedom of domestic movement for women',
                     'Freedom of domestic movement for men',
                     'Freedom of discussion for men',
                     'Print/broadcast censorship effort',
                     'Media self-censorship')) %>%
  mutate(relativeImportance = importance/sum(importance)) %>%
  ggplot() +
  geom_segment(aes(x = reorder(feature, relativeImportance), y = 0, xend = feature, yend = relativeImportance)) +
  geom_point(aes(x = reorder(feature, relativeImportance), y = relativeImportance, size = 1.2),
             color = '#ad7a99', show.legend = FALSE) +
  xlab('') +
  ylab('Relative Importance') + 
  ggtitle('Variable Importance in Prediction of Gender Equality') +
  coord_flip() +
  theme(text = element_text(family = 'lato'))
```

```{r}
ggsave('output-charts/genderEquality.png', width = 9, height = 6, device='png')
```


## Visualizing the impact of important variables

Ultimately, we want to take these important variables and see what their relationship to gender equality actually is. For this visualization, we are just going to look at simple scatter plots.

```{r}
important_vars <- c('v_23_08', 'v_23_09', 'v_23_06', 'v_23_07', 'v_21_02', 'v_21_01', 'v_23_02', 'v_23_04', 
                    'v_22_06', 'v_22_31', 'v_22_32', 'v_22_33', 'v_22_05', 'v_22_03', 'v_22_01')

important_names <- c('Exclusion by social group index (inverted)',
                     'Exculsion by urban/rural location (inverted)',
                     'Exclusion by socio-economic group (inverted)',
                     'Exclusion by political group index (inverted)',
                     'Access to justice for women',
                     'Access to justice for men',
                     'Social group equality in respect to civil liberties',
                     'Power distributed by social group',
                     'Freedom of academic and cultural expression',
                     'Freedom of foreign movement',
                     'Freedom of domestic movement for women',
                     'Freedom of domestic movement for men',
                     'Freedom of discussion for men',
                     'Media self-censorship',
                     'Print/broadcast censorship effort')
```

```{r}
importance <- imp %>% mutate(relativeImportance = importance/sum(importance))
importance
```


```{r}
for(i in 1:length(important_vars)){
  importancePercent <- percent(importance[importance$variable==important_vars[i],'relativeImportance'])
  plot <- countries %>%
    ggplot(aes(x=C_SD23C, y=eval(as.name(important_vars[i])))) +
    geom_point(size=0.5, color = '#ad7a99') + 
    ylab(important_names[i]) + 
    xlab('Freedom of religion') +
    ggtitle(paste(important_names[i], 'versus gender equality: all observations'),
            subtitle = paste(important_names[i], 'is', importancePercent, 'important in predicting gender equality')) +
    theme(text = element_text(family = 'lato'))
  ggsave(paste0('output-charts/gender-equality-relationships/', important_vars[i], '.png'), device='png',
         width = 8, height = 7)
}
```


